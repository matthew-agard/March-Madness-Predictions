{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard Python libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from IPython.display import display\n",
    "import re\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from datetime import datetime\n",
    "start_year = 1993\n",
    "curr_year = datetime.now().year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom API\n",
    "from sys import path\n",
    "\n",
    "path.append('../API/eda')\n",
    "from data_visualizations import get_yearly_base_rates, get_seed_pairs, format_plot\n",
    "\n",
    "path.append('../API/fetch')\n",
    "import data_fetch as fetch\n",
    "\n",
    "path.append('../API/model')\n",
    "from model_selection import get_cv_models\n",
    "from model_evaluation import evaluate_cv_models, get_classification_report\n",
    "\n",
    "path.append('../API/preprocess')\n",
    "from data_pipeline import dataset_pipeline, feature_pipeline, bracket_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Fetching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perceived Predictors\n",
    "\n",
    "Naturally, it will be vitally important to scrape available data that is pertinent to deciding the outcome of an NCAA March Madness game between any two given teams. To successfully do so, we must break down what are generally the most influential elements of a basketball team's success.\n",
    "\n",
    "<br>Overall team performance during the regular season is generally a good indicator of how a team will perform in March Madness. This would be captured by statistics, both basic and advanced, such as the following:\n",
    "<br>**Season Record (%)\n",
    "<br>Conference Record (%); could be important given that the tournament is split into regions\n",
    "<br>Regular Season Record vs. Tourney Opponent (%); set to theoretical discrete probability of 50% if no such matchups exist \n",
    "<br>Strength of Schedule (SOS); measures the difficulty of the teams played (higher number = greater difficulty)\n",
    "<br>Top 25 Ranking (boolean); considered a consensus top-tier team\n",
    "<br>Shots Made per Game (FG, 3P, FT)\n",
    "<br>Point Differential per Game; measures how dominant/unsuccessful you are at outscoring your opponent on average\n",
    "<br>Misc. Team Stats per Game (Rebounds, Assists, Blocks, etc.)**\n",
    "\n",
    "<br>It's important to note that in the NCAA, more so than the NBA, experienced coaches can have just as much of an impact on a game's outcome as the players themselves. Hence, it's reasonable to assume that the following statistics could also be solid indicators:\n",
    "**<br>Coach March Madness Appearances\n",
    "<br>Coach Sweet Sixteen Appearances\n",
    "<br>Coach Final Four Appearances\n",
    "<br>Coach Championships Won**\n",
    "\n",
    "<br>And lastly, we need the data for the structure of the tournaments themselves:\n",
    "**<br>Favorite Seed\n",
    "<br>Underdog Seed\n",
    "<br>Round Number (0-6)\n",
    "<br>Game Outcome (boolean); did the underdog upset the favorite?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Team Regular Season Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rk</th>\n",
       "      <th>School</th>\n",
       "      <th>G</th>\n",
       "      <th>W</th>\n",
       "      <th>L</th>\n",
       "      <th>W-L%</th>\n",
       "      <th>SRS</th>\n",
       "      <th>SOS</th>\n",
       "      <th>Unnamed: 8</th>\n",
       "      <th>W.1</th>\n",
       "      <th>...</th>\n",
       "      <th>FT</th>\n",
       "      <th>FTA</th>\n",
       "      <th>FT%</th>\n",
       "      <th>ORB</th>\n",
       "      <th>TRB</th>\n",
       "      <th>AST</th>\n",
       "      <th>STL</th>\n",
       "      <th>BLK</th>\n",
       "      <th>TOV</th>\n",
       "      <th>PF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Air Force</td>\n",
       "      <td>28</td>\n",
       "      <td>9</td>\n",
       "      <td>19</td>\n",
       "      <td>.321</td>\n",
       "      <td>-7.45</td>\n",
       "      <td>2.05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>409</td>\n",
       "      <td>584</td>\n",
       "      <td>.700</td>\n",
       "      <td>NaN</td>\n",
       "      <td>965</td>\n",
       "      <td>285</td>\n",
       "      <td>178</td>\n",
       "      <td>109</td>\n",
       "      <td>385</td>\n",
       "      <td>546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Akron</td>\n",
       "      <td>26</td>\n",
       "      <td>8</td>\n",
       "      <td>18</td>\n",
       "      <td>.308</td>\n",
       "      <td>-10.69</td>\n",
       "      <td>-5.07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>320</td>\n",
       "      <td>493</td>\n",
       "      <td>.649</td>\n",
       "      <td>NaN</td>\n",
       "      <td>795</td>\n",
       "      <td>315</td>\n",
       "      <td>163</td>\n",
       "      <td>47</td>\n",
       "      <td>352</td>\n",
       "      <td>573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Alabama-Birmingham</td>\n",
       "      <td>35</td>\n",
       "      <td>21</td>\n",
       "      <td>14</td>\n",
       "      <td>.600</td>\n",
       "      <td>10.82</td>\n",
       "      <td>5.68</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>456</td>\n",
       "      <td>650</td>\n",
       "      <td>.702</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1273</td>\n",
       "      <td>501</td>\n",
       "      <td>246</td>\n",
       "      <td>135</td>\n",
       "      <td>498</td>\n",
       "      <td>650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Alabama State</td>\n",
       "      <td>27</td>\n",
       "      <td>14</td>\n",
       "      <td>13</td>\n",
       "      <td>.519</td>\n",
       "      <td>-8.48</td>\n",
       "      <td>-9.70</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>541</td>\n",
       "      <td>767</td>\n",
       "      <td>.705</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1049</td>\n",
       "      <td>395</td>\n",
       "      <td>194</td>\n",
       "      <td>42</td>\n",
       "      <td>556</td>\n",
       "      <td>567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>29</td>\n",
       "      <td>16</td>\n",
       "      <td>13</td>\n",
       "      <td>.552</td>\n",
       "      <td>9.66</td>\n",
       "      <td>7.83</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>458</td>\n",
       "      <td>702</td>\n",
       "      <td>.652</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1117</td>\n",
       "      <td>337</td>\n",
       "      <td>185</td>\n",
       "      <td>120</td>\n",
       "      <td>487</td>\n",
       "      <td>539</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Rk              School   G   W   L  W-L%     SRS    SOS  Unnamed: 8 W.1  \\\n",
       "0  1           Air Force  28   9  19  .321   -7.45   2.05         NaN   3   \n",
       "1  2               Akron  26   8  18  .308  -10.69  -5.07         NaN   3   \n",
       "2  3  Alabama-Birmingham  35  21  14  .600   10.82   5.68         NaN   5   \n",
       "3  4       Alabama State  27  14  13  .519   -8.48  -9.70         NaN   9   \n",
       "4  5             Alabama  29  16  13  .552    9.66   7.83         NaN   7   \n",
       "\n",
       "   ...   FT  FTA   FT%  ORB   TRB  AST  STL  BLK  TOV   PF  \n",
       "0  ...  409  584  .700  NaN   965  285  178  109  385  546  \n",
       "1  ...  320  493  .649  NaN   795  315  163   47  352  573  \n",
       "2  ...  456  650  .702  NaN  1273  501  246  135  498  650  \n",
       "3  ...  541  767  .705  NaN  1049  395  194   42  556  567  \n",
       "4  ...  458  702  .652  NaN  1117  337  185  120  487  539  \n",
       "\n",
       "[5 rows x 38 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fetch.get_team_data(url=f\"https://www.sports-reference.com/cbb/seasons/{start_year}-school-stats.html\",\n",
    "                    attrs={'id': 'basic_school_stats'}).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rk</th>\n",
       "      <th>School</th>\n",
       "      <th>G</th>\n",
       "      <th>W</th>\n",
       "      <th>L</th>\n",
       "      <th>W-L%</th>\n",
       "      <th>SRS</th>\n",
       "      <th>SOS</th>\n",
       "      <th>Unnamed: 8</th>\n",
       "      <th>W.1</th>\n",
       "      <th>...</th>\n",
       "      <th>3PAr</th>\n",
       "      <th>TS%</th>\n",
       "      <th>TRB%</th>\n",
       "      <th>AST%</th>\n",
       "      <th>STL%</th>\n",
       "      <th>BLK%</th>\n",
       "      <th>eFG%</th>\n",
       "      <th>TOV%</th>\n",
       "      <th>ORB%</th>\n",
       "      <th>FT/FGA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Air Force</td>\n",
       "      <td>28</td>\n",
       "      <td>9</td>\n",
       "      <td>19</td>\n",
       "      <td>.321</td>\n",
       "      <td>-7.45</td>\n",
       "      <td>2.05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>.279</td>\n",
       "      <td>.500</td>\n",
       "      <td>49.9</td>\n",
       "      <td>44.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.6</td>\n",
       "      <td>.458</td>\n",
       "      <td>17.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>.263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Akron</td>\n",
       "      <td>26</td>\n",
       "      <td>8</td>\n",
       "      <td>18</td>\n",
       "      <td>.308</td>\n",
       "      <td>-10.69</td>\n",
       "      <td>-5.07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>.277</td>\n",
       "      <td>.517</td>\n",
       "      <td>51.1</td>\n",
       "      <td>54.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.5</td>\n",
       "      <td>.488</td>\n",
       "      <td>18.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>.241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Alabama-Birmingham</td>\n",
       "      <td>35</td>\n",
       "      <td>21</td>\n",
       "      <td>14</td>\n",
       "      <td>.600</td>\n",
       "      <td>10.82</td>\n",
       "      <td>5.68</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>.270</td>\n",
       "      <td>.527</td>\n",
       "      <td>52.2</td>\n",
       "      <td>56.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.6</td>\n",
       "      <td>.494</td>\n",
       "      <td>17.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>.228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Alabama State</td>\n",
       "      <td>27</td>\n",
       "      <td>14</td>\n",
       "      <td>13</td>\n",
       "      <td>.519</td>\n",
       "      <td>-8.48</td>\n",
       "      <td>-9.70</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>.203</td>\n",
       "      <td>.557</td>\n",
       "      <td>51.3</td>\n",
       "      <td>46.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.8</td>\n",
       "      <td>.518</td>\n",
       "      <td>20.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>.305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>29</td>\n",
       "      <td>16</td>\n",
       "      <td>13</td>\n",
       "      <td>.552</td>\n",
       "      <td>9.66</td>\n",
       "      <td>7.83</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>.299</td>\n",
       "      <td>.541</td>\n",
       "      <td>51.7</td>\n",
       "      <td>43.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.9</td>\n",
       "      <td>.513</td>\n",
       "      <td>19.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>.271</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Rk              School   G   W   L  W-L%     SRS    SOS  Unnamed: 8 W.1  \\\n",
       "0  1           Air Force  28   9  19  .321   -7.45   2.05         NaN   3   \n",
       "1  2               Akron  26   8  18  .308  -10.69  -5.07         NaN   3   \n",
       "2  3  Alabama-Birmingham  35  21  14  .600   10.82   5.68         NaN   5   \n",
       "3  4       Alabama State  27  14  13  .519   -8.48  -9.70         NaN   9   \n",
       "4  5             Alabama  29  16  13  .552    9.66   7.83         NaN   7   \n",
       "\n",
       "   ...  3PAr   TS%  TRB%  AST%  STL% BLK%  eFG%  TOV% ORB% FT/FGA  \n",
       "0  ...  .279  .500  49.9  44.3   NaN  9.6  .458  17.4  NaN   .263  \n",
       "1  ...  .277  .517  51.1  54.3   NaN  5.5  .488  18.4  NaN   .241  \n",
       "2  ...  .270  .527  52.2  56.4   NaN  9.6  .494  17.8  NaN   .228  \n",
       "3  ...  .203  .557  51.3  46.4   NaN  2.8  .518  20.7  NaN   .305  \n",
       "4  ...  .299  .541  51.7  43.1   NaN  8.9  .513  19.4  NaN   .271  \n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fetch.get_team_data(url=f\"https://www.sports-reference.com/cbb/seasons/{start_year}-advanced-school-stats.html\", \n",
    "                    attrs={'id': 'adv_school_stats'}).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Team Rankings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Team</th>\n",
       "      <th>Top_25</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>North Carolina</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Kentucky</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Duke</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Indiana</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Cincinnati</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Team Top_25\n",
       "2  North Carolina      1\n",
       "3        Kentucky      1\n",
       "4            Duke      1\n",
       "5         Indiana      1\n",
       "6      Cincinnati      1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fetch.get_rankings_data(url=f\"https://www.sports-reference.com/cbb/seasons/{start_year}-ratings.html\").head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coach Tournament Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Coach_Team</th>\n",
       "      <th>MM</th>\n",
       "      <th>S16</th>\n",
       "      <th>F4</th>\n",
       "      <th>Champs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Air Force</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Akron</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Alabama</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Alabama-Birmingham</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Alabama State</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Coach_Team  MM S16 F4 Champs\n",
       "2           Air Force                  \n",
       "3               Akron                  \n",
       "4             Alabama                  \n",
       "5  Alabama-Birmingham  11   5  2       \n",
       "6       Alabama State                  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fetch.get_coach_data(url=f\"https://www.sports-reference.com/cbb/seasons/{start_year}-coaches.html\").head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tournament Game Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Round</th>\n",
       "      <th>Seed</th>\n",
       "      <th>Team</th>\n",
       "      <th>Score</th>\n",
       "      <th>Seed.1</th>\n",
       "      <th>Team.1</th>\n",
       "      <th>Score.1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1993</td>\n",
       "      <td>First Round</td>\n",
       "      <td>1</td>\n",
       "      <td>UNC</td>\n",
       "      <td>85</td>\n",
       "      <td>16</td>\n",
       "      <td>East Carolina</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1993</td>\n",
       "      <td>First Round</td>\n",
       "      <td>8</td>\n",
       "      <td>Rhode Island</td>\n",
       "      <td>74</td>\n",
       "      <td>9</td>\n",
       "      <td>Purdue</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1993</td>\n",
       "      <td>First Round</td>\n",
       "      <td>5</td>\n",
       "      <td>St. John's (NY)</td>\n",
       "      <td>85</td>\n",
       "      <td>12</td>\n",
       "      <td>Texas Tech</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1993</td>\n",
       "      <td>First Round</td>\n",
       "      <td>4</td>\n",
       "      <td>Arkansas</td>\n",
       "      <td>94</td>\n",
       "      <td>13</td>\n",
       "      <td>Holy Cross</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1993</td>\n",
       "      <td>First Round</td>\n",
       "      <td>6</td>\n",
       "      <td>Virginia</td>\n",
       "      <td>78</td>\n",
       "      <td>11</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>1993</td>\n",
       "      <td>Sweet Sixteen</td>\n",
       "      <td>3</td>\n",
       "      <td>Vanderbilt</td>\n",
       "      <td>59</td>\n",
       "      <td>7</td>\n",
       "      <td>Temple</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>1993</td>\n",
       "      <td>Elite Eight</td>\n",
       "      <td>1</td>\n",
       "      <td>Michigan</td>\n",
       "      <td>77</td>\n",
       "      <td>7</td>\n",
       "      <td>Temple</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>1993</td>\n",
       "      <td>Final Four</td>\n",
       "      <td>1</td>\n",
       "      <td>UNC</td>\n",
       "      <td>78</td>\n",
       "      <td>2</td>\n",
       "      <td>Kansas</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>1993</td>\n",
       "      <td>Final Four</td>\n",
       "      <td>1</td>\n",
       "      <td>Kentucky</td>\n",
       "      <td>78</td>\n",
       "      <td>1</td>\n",
       "      <td>Michigan</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>1993</td>\n",
       "      <td>National Championship</td>\n",
       "      <td>1</td>\n",
       "      <td>UNC</td>\n",
       "      <td>77</td>\n",
       "      <td>1</td>\n",
       "      <td>Michigan</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>63 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Year                  Round  Seed             Team  Score  Seed.1  \\\n",
       "0   1993            First Round     1              UNC     85      16   \n",
       "1   1993            First Round     8     Rhode Island     74       9   \n",
       "2   1993            First Round     5  St. John's (NY)     85      12   \n",
       "3   1993            First Round     4         Arkansas     94      13   \n",
       "4   1993            First Round     6         Virginia     78      11   \n",
       "..   ...                    ...   ...              ...    ...     ...   \n",
       "58  1993          Sweet Sixteen     3       Vanderbilt     59       7   \n",
       "59  1993            Elite Eight     1         Michigan     77       7   \n",
       "60  1993             Final Four     1              UNC     78       2   \n",
       "61  1993             Final Four     1         Kentucky     78       1   \n",
       "62  1993  National Championship     1              UNC     77       1   \n",
       "\n",
       "           Team.1  Score.1  \n",
       "0   East Carolina       65  \n",
       "1          Purdue       68  \n",
       "2      Texas Tech       67  \n",
       "3      Holy Cross       64  \n",
       "4       Manhattan       66  \n",
       "..            ...      ...  \n",
       "58         Temple       67  \n",
       "59         Temple       72  \n",
       "60         Kansas       68  \n",
       "61       Michigan       81  \n",
       "62       Michigan       71  \n",
       "\n",
       "[63 rows x 8 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fetch.get_hist_bracket(url=f'https://www.sports-reference.com/cbb/postseason/{start_year}-ncaa.html', year=start_year)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Pipeline\n",
    "\n",
    "Below is the output of a merge of the datasets displayed above (after they've been cleaned). Once we remove the features with nulls that won't be imputed, we can begin our exploratory data analysis (EDA)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cannot convert the series to <class 'float'>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-d01fae362158>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mmm_matchups_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'{curr_year}_march_madness_hist_data.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mexcept\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\March Madness\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    687\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 688\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    689\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\March Madness\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    453\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 454\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    455\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\March Madness\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    947\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 948\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    949\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\March Madness\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1179\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"c\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1180\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1181\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\March Madness\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   2009\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2010\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2011\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '2021_march_madness_hist_data.csv'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-d01fae362158>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mmm_matchups_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'{curr_year}_march_madness_hist_data.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mexcept\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mmm_matchups_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataset_pipeline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstart_year\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcurr_year\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0mmm_matchups_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'{curr_year}_march_madness_hist_data.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\Personal Projects\\Data Science & Machine Learning\\March Madness Predictions\\API\\preprocess\\data_pipeline.py\u001b[0m in \u001b[0;36mdataset_pipeline\u001b[1;34m(years)\u001b[0m\n\u001b[0;32m    189\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    190\u001b[0m         \u001b[1;31m# Merge tournament data to regular season data to create complete dataset for given year\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 191\u001b[1;33m         \u001b[0myear_mm_data_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhist_tournament_games\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0myear\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mall_season_stats_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclean_season_basic_df\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    192\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    193\u001b[0m         \u001b[1;31m# Concatenate current year's data to DataFrame containing remainder of dataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\Personal Projects\\Data Science & Machine Learning\\March Madness Predictions\\API\\preprocess\\data_pipeline.py\u001b[0m in \u001b[0;36mhist_tournament_games\u001b[1;34m(year, all_stats, basic_stats)\u001b[0m\n\u001b[0;32m    161\u001b[0m     \u001b[1;31m# Clean & merge regular season data to tournament games (if they exist for given year)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    162\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mmm_games_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 163\u001b[1;33m         \u001b[0mclean_mm_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclean_tourney_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0myear\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmm_games_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclean_all_season_stats_df\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    164\u001b[0m         \u001b[0mmm_data_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmerge_clean_tourney_games\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclean_mm_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclean_all_season_stats_df\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    165\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\Personal Projects\\Data Science & Machine Learning\\March Madness Predictions\\API\\preprocess\\data_clean.py\u001b[0m in \u001b[0;36mclean_tourney_data\u001b[1;34m(year, mm_df, season_df)\u001b[0m\n\u001b[0;32m    142\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    143\u001b[0m     \u001b[1;31m# Transform team listings into favorite-underdog matchups (using seeds & regular season record)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 144\u001b[1;33m     \u001b[0mfaves_unds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_faves_underdogs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmm_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseason_df\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    145\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    146\u001b[0m     \u001b[1;31m# Create new features representing favorite-underdog matchups\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\Personal Projects\\Data Science & Machine Learning\\March Madness Predictions\\API\\preprocess\\feature_engineering.py\u001b[0m in \u001b[0;36mcreate_faves_underdogs\u001b[1;34m(mm_df, season_df)\u001b[0m\n\u001b[0;32m     87\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m             \u001b[1;31m# Get regular season win percentage for both teams\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 89\u001b[1;33m             \u001b[0mteam_win_pct\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseason_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mseason_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'School'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Team'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'W-L%'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     90\u001b[0m             \u001b[0mteam1_win_pct\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseason_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mseason_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'School'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Team.1'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'W-L%'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\March Madness\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    127\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    128\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mconverter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 129\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"cannot convert the series to {converter}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    130\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    131\u001b[0m     \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34mf\"__{converter.__name__}__\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: cannot convert the series to <class 'float'>"
     ]
    }
   ],
   "source": [
    "# Check if the historical data CSV exists, if it doesn't then create it\n",
    "try:\n",
    "    mm_matchups_df = pd.read_csv(f'{curr_year}_march_madness_hist_data.csv')\n",
    "except FileNotFoundError:\n",
    "    mm_matchups_df = dataset_pipeline(np.arange(start_year, curr_year - 1))\n",
    "    mm_matchups_df.to_csv(f'{curr_year}_march_madness_hist_data.csv', index=False)\n",
    "\n",
    "mm_matchups_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling Missing Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding the Nulls\n",
    "\n",
    "Recall that our cleaned dataset has a total of 1,747 March Madness games present, and each March Madness will consist of no more than 67 games (4 play-in games + 63 tournament games). As can be seen below, the advanced stats pertaining to personal fouls (PF) and turnovers (TOV) are the only features listed with no more than a season's worth of missing data. Given how rapidly the gameplay of college basketball has evolved over the time horizon of our dataset, imputing nulls on multiple years of March Madness data would likely be a futile effort. The features with a high volume of nulls (1> season) will be dropped from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Given that a feature has any nulls, find the number of nulls present\n",
    "true_nulls = fetch.get_feature_null_counts(mm_matchups_df)\n",
    "true_nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get turnover features from true_nulls\n",
    "tov_null_fills = [col for col in true_nulls.index if ('TOV' in col)]\n",
    "\n",
    "# Get personal foul features from true_nulls\n",
    "pf_null_fills = [col for col in true_nulls.index if ('PF' in col)]\n",
    "\n",
    "# All other features found in true_nulls are dropped from our original dataset\n",
    "null_drops = list(set(true_nulls.index) - set(tov_null_fills) - set(pf_null_fills))\n",
    "mm_matchups_df.drop(null_drops, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the rows containing all of the dataset's nulls to be imputed\n",
    "# This will be a useful reference to validate the proper imputation of the nulls\n",
    "tov_nulls_rows = fetch.get_null_rows(tov_null_fills, mm_matchups_df)\n",
    "pf_nulls_rows = fetch.get_null_rows(pf_null_fills, mm_matchups_df)\n",
    "\n",
    "display(tov_nulls_rows), display(pf_nulls_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What are the Distributions of the Features We Wish to Impute?\n",
    "\n",
    "Upon looking at the distributions below of all turnover and personal foul features, we can see that they closely resemble a normal distribution. Given this assumption, the features' means will serve as good values for imputing the nulls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the distributions of the dataset's turnover features\n",
    "tov_null_years = sorted(list(set(tov_nulls_rows['Year'])))\n",
    "\n",
    "for year in tov_null_years:\n",
    "    print(f\"{year} feature distributions\")\n",
    "    year_df = mm_matchups_df[mm_matchups_df['Year'] == year]\n",
    "    year_df[tov_null_fills].hist(figsize=(10, 5), layout=(len(tov_null_years), len(tov_null_fills)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the distributions of the dataset's personal foul features\n",
    "mm_matchups_df[pf_null_fills].hist(figsize=(10, 5), layout=(1, len(pf_null_fills)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impute TOV Nulls by Season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Retrieve TOV feature means by season; only include seasons that contain nulls\n",
    "tov_col_means = mm_matchups_df[tov_nulls_rows.columns].groupby('Year').mean()\n",
    "tov_col_means.loc[tov_null_years]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for year in tov_null_years:\n",
    "    for col in tov_null_fills:\n",
    "        # Get feature's rows with nulls for given year\n",
    "        col_fill_rows = tov_nulls_rows[tov_nulls_rows['Year'] == year].index\n",
    "        # Get feature's mean for given year\n",
    "        col_year_mean = np.round(tov_col_means.loc[year, col], 1)\n",
    "        # Impute nulls of interest\n",
    "        mm_matchups_df.loc[col_fill_rows, col] = mm_matchups_df.loc[col_fill_rows, col].fillna(col_year_mean)\n",
    "\n",
    "# Display rows that originally had nulls to see if they match discovered feature means\n",
    "mm_matchups_df.loc[tov_nulls_rows.index, tov_null_fills]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impute PF Nulls Using Entire Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve PF feature means; only found in one season\n",
    "pf_col_means = mm_matchups_df[pf_null_fills].mean()\n",
    "pf_col_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for col in pf_null_fills:\n",
    "    # Get feature's mean\n",
    "    col_mean = np.round(mm_matchups_df[col].mean(), 1)\n",
    "    # Impute nulls of interest\n",
    "    mm_matchups_df[col].fillna(col_mean, inplace=True)\n",
    "    \n",
    "# Display rows that originally had nulls to see if they match discovered feature means\n",
    "mm_matchups_df.loc[pf_nulls_rows.index, pf_null_fills]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis (EDA)\n",
    "\n",
    "As any good data scientist should do, there are a few questions I hope to address in my EDA:\n",
    " - What is our bracket's accuracy if we guess the favorite always wins?\n",
    " - How often do upsets occur in a given year's March Madness?\n",
    " - What is the distribution of upsets across the tournament rounds?\n",
    " - Which seeding combinations are most likely to produce upsets?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is our Bracket's Accuracy if We Guess the Favorite Always Wins?\n",
    "\n",
    "This is a strategy many of us have employed at least once while filling out a March Madness bracket, myself included. This is a classic EDA question which explores the idea of the base rate: historically, how often would we be right if we always assumed the favorite won the March Madness matchup? ~68.6% of our predictions would be correct according to our data, approximately 2 out of every 3 games. This means that for any model to be of value to us, it must demonstrate >68.6% of its predictions are correct.\n",
    "\n",
    "In college basketball, the best (and thus most impactful) players typically leave the NCAA after no more than 2 years. Thus, a 2-year moving average was chosen to illustrate the base rate's trends as new impactful players participate in March Madness. Our base rate is maintained fairly consistently over time, with a few exceptions scattered across the dataset's time horizon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each season's base rate\n",
    "yearly_base_rates = get_yearly_base_rates(mm_matchups_df)\n",
    "# Dataset's mean base rate\n",
    "mean_base_rate = np.round(yearly_base_rates.mean(), 3)\n",
    "# Moving average\n",
    "years_ma = 2\n",
    "base_rate_ma = np.round(yearly_base_rates.rolling(years_ma).mean(), 3)\n",
    "\n",
    "# Plot findings\n",
    "plt.figure(figsize=(9, 6))\n",
    "\n",
    "plt.plot(yearly_base_rates.index, [mean_base_rate] * len(yearly_base_rates), color='k', linewidth=3, label=f'Mean ({mean_base_rate})')\n",
    "plt.plot(yearly_base_rates.index, base_rate_ma, color='r', linewidth=3, label=f'{years_ma}-Yr MA')\n",
    "plt.bar(yearly_base_rates.index, yearly_base_rates)\n",
    "\n",
    "format_plot(title='Dataset Base Rate Trends', xlabel='Season', ylabel='Base Rate')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How Often Do Upsets Occur in a Given Year's March Madness?\n",
    "\n",
    "If favorites win March Madness matchups ~68.6% of the time, then we can conclude the underdogs are winning the other 31.4%; this translates to approximately 20 upsets per year. This knowledge gives us insight into how many upsets we should expect our model to predict (i.e. 25 is likely too high, 15 is likely too low).\n",
    "\n",
    "A 2-year moving average has been employed once again to highlight the trends present across the dataset's time horizon. At first it may appear to be more volatile than the base rate trends, but this is simply due to the scale of the y-axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each season's upset count\n",
    "yearly_upsets = mm_matchups_df.groupby('Year').agg({'Underdog_Upset': 'sum'})\n",
    "# Dataset's mean upset count\n",
    "mean_upsets = np.round(yearly_upsets['Underdog_Upset'].mean(), 1)\n",
    "# Moving average\n",
    "upsets_ma = np.round(yearly_upsets.rolling(years_ma).mean(), 1)\n",
    "\n",
    "# Plot findings\n",
    "plt.figure(figsize=(9, 6))\n",
    "\n",
    "plt.plot(yearly_upsets.index, [mean_upsets] * len(yearly_upsets), color='k', linewidth=3, label=f'Mean ({mean_upsets})')\n",
    "plt.plot(yearly_upsets.index, upsets_ma, color='r', linewidth=3, label=f'{years_ma}-Yr MA')\n",
    "plt.bar(yearly_upsets.index, yearly_upsets['Underdog_Upset'])\n",
    "\n",
    "format_plot(title='Dataset Upsets Volume Trends', xlabel='Season', ylabel='Upsets')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is the Distribution of Upsets Across the Tournament Rounds?\n",
    "\n",
    "Of the 20 upsets that we can expect in any given March Madness, the visualization below gives us an idea of how many upsets we can expect in each round. Nearly 70% of all upsets happen in the first 2 rounds, which is sensible given that 75% of all games are held in the first 2 rounds. Fewer upsets in each successive round is expected not only because of a diminished volume of games, but also a greater saturation of top-tier teams amongst the remaining teams in contention. We should expect our model to follow a similar pattern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve data about March Madness matchup seed pairings\n",
    "seed_pairs = get_seed_pairs(mm_matchups_df)\n",
    "# Extract seed pairs that resulted in upsets\n",
    "upset_pairs = seed_pairs[seed_pairs['Underdog_Upset'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group upset seed pairs by round and count them\n",
    "upset_rounds_freq = upset_pairs['Round'].value_counts(normalize=True)\n",
    "\n",
    "# Plot findings\n",
    "upset_rounds_freq.plot(figsize=(9, 6), kind='bar', rot=15)\n",
    "\n",
    "format_plot(title='Dataset Upsets by Round', xlabel='Round', ylabel='Ratio of Upsets')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Which Seeding Combinations are the Most Likely to Produce Upsets?\n",
    "\n",
    "Suppose our model predicts 12 upsets in the first round, even though we should only expect 9 according to our EDA. In the event this type of situation arises, it'd be valuable to know which seed pairings are most likely to produce upsets so we could discard 3 of the 12 first round upsets with the lowest upset likelihoods.\n",
    "\n",
    "Only the top 25 upset likelihoods are shown because our EDA also revealed we should expect no more than 25 upsets in a given year. We can see once again that the overwhelming majority of upsets occur in the first round, particularly in the 4 seed pairings that are the most evenly matched (Seeds 8 vs. 9 through Seeds 5 vs. 12). Our model should emulate this behavior fairly closely in its upset predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group upsets by seed pairing and count them\n",
    "upset_pairs_freq = np.round(upset_pairs['Pairs'].value_counts(normalize=True)[:25], 3)\n",
    "\n",
    "# Plot findings\n",
    "upset_pairs_freq.plot(figsize=(9, 6), kind='bar', rot=35)\n",
    "\n",
    "format_plot(title='Dataset Upsets by Seed Pair', xlabel='Seed Pair', ylabel='Ratio of Upsets')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering & Analysis\n",
    "\n",
    "Below we can see our original feature matrix (X) and then our feature matrix prepped for model fitting (prep_all_X). This transformation is performed by passing X through the feature pipeline. \n",
    "\n",
    "One of the primary actions that transpires in the pipeline is subtracting the favorites' stats from the underdogs' stats in each matchups to create underdog relative features. This not only retains virtually all of our information, but also improves computation speed and reduces the likelihood of overfitting.\n",
    "\n",
    "The second primary action is the scaling of our numerical features. This conversion of all numerical features to a normal distribution is important because it nullifies the possibility of features' number ranges being a deciding factor in a model's  learning process.\n",
    "\n",
    "Should you be curious about the more intricate details, you may refer to the feature_pipeline() custom API documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Drop unneeded features\n",
    "mm_matchups_df.drop(['Year', 'Team_Favorite', 'Team_Underdog'], axis=1, inplace=True)\n",
    "# Store rounds data (for visualizations)\n",
    "all_rounds = mm_matchups_df['Round']\n",
    "\n",
    "# Create feature matrix and target variable\n",
    "X = mm_matchups_df.drop('Underdog_Upset', axis=1)\n",
    "y = mm_matchups_df['Underdog_Upset']\n",
    "\n",
    "display(X), display(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll stratify the split of our training & test datasets according to the target variable's \n",
    "# distribution so our model can learn the trends observed in our EDA\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "# Drop round data because it's already stored in previous cell\n",
    "X_train.drop('Round', axis=1, inplace=True)\n",
    "X_test.drop('Round', axis=1, inplace=True)\n",
    "\n",
    "# Pass datasets through feature pipeline to prep them for model fitting\n",
    "fit_df = X_train\n",
    "# All datasets will be scaled based on fit found for training dataset\n",
    "prep_X_train = feature_pipeline(X_train, fit_df)\n",
    "prep_X_test = feature_pipeline(X_test, fit_df)\n",
    "\n",
    "prep_all_X = pd.concat([prep_X_train, prep_X_test])\n",
    "prep_all_X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What are the Distributions of all our Features?\n",
    "\n",
    "The illustration below shows us the impact of the feature scaling mentioned earlier. Our features are predominantly normally distributed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prep_all_X.hist(figsize=(15, 10))\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What Features have the Greatest Predictive Power?\n",
    "The plot below represents an important concept in data science & machine learning: normalized information gain. It's a ratio of how much predictive power can be attributed to each feature in a feature matrix; these values should sum to 1, or 100% of the predictive power.\n",
    "\n",
    "We can see underdog relative games (Underdog_Rel_G) has a staggering lead over the remaining features - almost 25% of predictive power can be attributed to that one feature alone! This is sensible because it highlights how March Madness matchup favorites play more games together than their underdog opponents, which gives them more experience. This strong predictive power may negatively impact our predictions for this 2020-21 season because the COVID-19 pandemic messed up the schedules of many traditionally top-tier teams this year.\n",
    "\n",
    "The remaining dominant features are equally sensible: strength of schedule (SOS; measures the caliber of their regular season opponents), win-loss % (W-L%; what was their regular season record), and point differential (PtsDiff; what was their average margin of victory/defeat)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit data to a Random Forest to find feature importances\n",
    "rf = RandomForestClassifier().fit(prep_X_train, y_train)\n",
    "\n",
    "# Sort features & their corresponding values in by importance\n",
    "importances = rf.feature_importances_\n",
    "feat_importances = prep_all_X.columns[np.argsort(importances)]\n",
    "feat_values = np.sort(importances)\n",
    "\n",
    "# Plot findings\n",
    "plt.figure(figsize=(9, 6))\n",
    "plt.barh(feat_importances, feat_values)\n",
    "\n",
    "format_plot(title='Feature Importances', xlabel='Normalized Information Gain', ylabel='Features')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What are the Correlations Between Features?\n",
    "\n",
    "Though correlation differs from information gain, we still see the same features dominating the landscape. Even more interesting is that they're dominating to approximately the same degree that they were in our information gain plot above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature matrix's correlations to target variable, then sort by absolute value\n",
    "prep_X_y = prep_X_train.merge(y_train, left_index=True, right_index=True)\n",
    "abs_desc_corr = np.abs(prep_X_y.corr().loc['Underdog_Upset']).sort_values()\n",
    "abs_desc_corr.drop('Underdog_Upset', inplace=True)\n",
    "\n",
    "# Plot findings\n",
    "plt.figure(figsize=(9, 6))\n",
    "plt.barh(abs_desc_corr.index, abs_desc_corr.values)\n",
    "\n",
    "format_plot(title='Target Variable Correlation', xlabel='Absolute Correlation Value', ylabel='Features')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Selection\n",
    "\n",
    "1,747 total records in a dataset isn't much, so it was necessary to employ cross-validation (CV) on the training dataset to simulate the presence of a validation set. I saw from a quick online search that a 60%-20%-20% training-validation-test set split was ideal, which required me to perform 4 CVs in my grid and randomized searches.\n",
    "\n",
    "The models were evaluated based upon both the accuracy and AUC metrics. The Logistic Regression (LogReg) and Support Vector Machine (SVM) models are the clear frontrunners, with the SVM having the slight edge. However, choosing the LogReg model is still best because of its superior interpretability and capability for probability estimation if we find it necessary to adjust our model's prediction thresholds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform CV on chosen models, then assess their respective performances\n",
    "cv_models = get_cv_models(y)\n",
    "model_performance = evaluate_cv_models(cv_models, prep_X_train, y_train)\n",
    "\n",
    "model_performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the performance of each model against the Accuracy & AUC metrics\n",
    "model_performance[['Mean_Accuracy', 'Mean_AUC']].plot(figsize=(9, 6), kind='barh', xticks=np.arange(0, 0.9, 0.05))\n",
    "\n",
    "format_plot(title='Model Performance', xlabel='Metric Value', ylabel='Model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot the stability of our top model choices by evaluating Accuracy & AUC standard deviations\n",
    "model_performance.loc[['SVM', 'LogReg'], ['Mean_Accuracy_Std', 'Mean_AUC_Std']].plot(\n",
    "    figsize=(9, 6), kind='barh', xticks=np.arange(0.01, 0.05, 0.01)\n",
    ")\n",
    "\n",
    "format_plot(title='Model Stability', xlabel='Standard Deviation (Std)', ylabel='Model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation\n",
    "\n",
    "The distribution of the predicted upsets across the tournament rounds in our test set is very similar to the true target variable values we observed in our original dataset, with the primary differences being fewer first round upsets and more third round (Sweet 16) upsets than expected. The upsets by seed pairing also shows strong similarities to our original dataset's trends.\n",
    "\n",
    "The confusion matrix at the end of this section allows us to see how this model performs in relation to precision (false positives; type I error) and recall (false negatives; type II error). Interestingly, the only metric that appears to be subpar is the recall for predicting an upset (when Underdog_Upset == 1). This suggests our model could be a little conversative and not pick upsets when it actually should, so that's important to keep in mind as we transition into making predictions for this year's March Madness matchups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify best model to use, then make predictions with said model\n",
    "best_model = cv_models['LogReg'][-1].best_estimator_\n",
    "y_preds = best_model.predict(prep_X_test)\n",
    "\n",
    "display(best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate all visualization data into a single DataFrame\n",
    "test_game_data = pd.concat([y_test, all_rounds, mm_matchups_df[['Seed_Favorite', 'Seed_Underdog']]], \n",
    "                           join='inner', axis=1).drop('Underdog_Upset', axis=1)\n",
    "# Overwrite the actual target variable (used for the join) with the model's predictions\n",
    "test_game_data['Underdog_Upset'] = y_preds\n",
    "\n",
    "# Get seed pairs data\n",
    "test_seed_pairs = get_seed_pairs(test_game_data)\n",
    "# Extract seed pairs that resulted in upsets\n",
    "test_upset_pairs = test_seed_pairs[test_seed_pairs['Underdog_Upset'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group upset seed pairs by round and count them\n",
    "test_upset_rounds_freq = test_upset_pairs['Round'].value_counts(normalize=True)\n",
    "\n",
    "# Plot findings\n",
    "test_upset_rounds_freq.plot(figsize=(9, 6), kind='bar', rot=15)\n",
    "\n",
    "format_plot(title='Test Set Upsets by Round', xlabel='Round', ylabel='Ratio of Upsets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Group upsets by seed pairing and count them\n",
    "test_upset_pairs_freq = np.round(test_upset_pairs['Pairs'].value_counts(normalize=True)[:25], 3)\n",
    "\n",
    "# Plot findings\n",
    "test_upset_pairs_freq.plot(figsize=(9, 6), kind='bar', rot=35)\n",
    "\n",
    "format_plot(title='Test Set Upsets by Seed Pair', xlabel='Seed Pair', ylabel='Ratio of Upsets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show confusion matrix for model's predictions\n",
    "report = get_classification_report(y_test, y_preds)\n",
    "print(\"Test Set Metrics Report \\n\\n\", report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2021 March Madness Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Pipeline\n",
    "\n",
    "We first scrape ESPN for the starting matchups in the play-in and the first round. We then automate the prediction of all rounds in the March Madness bracket. In short, the winners predicted from the first round (filled with predicted play-in winners) are reformatted to create matchups for the second round. Those second round winners are then reformatted into the third round, and so on and so forth until a champion is crowned.\n",
    "\n",
    "Should you be curious about the more intricate details, you may refer to the bracket_pipeline() custom API documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Check if the starting bracket CSV exists, if it doesn't then create it\n",
    "try:\n",
    "    curr_bracket_df = pd.read_csv(f'{curr_year}_march_madness_curr_start_bracket.csv')\n",
    "except FileNotFoundError:\n",
    "    curr_bracket_df = fetch.get_current_bracket('http://www.espn.com/mens-college-basketball/tournament/bracket')\n",
    "    curr_bracket_df.to_csv(f'{curr_year}_march_madness_curr_start_bracket.csv', index=False)\n",
    "\n",
    "# Extract play-in matchups\n",
    "play_in = curr_bracket_df[:4]\n",
    "play_in = play_in.reindex([0, 1, 3, 2])\n",
    "\n",
    "# Extract first round matchups\n",
    "first_round = curr_bracket_df[4:]\n",
    "first_round.index = range(len(first_round))\n",
    "\n",
    "display(play_in), display(first_round)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Create DataFrame with all March Madness predictions\n",
    "bracket_preds = bracket_pipeline(curr_year, play_in, first_round, best_model, fit_df, null_drops)\n",
    "display(bracket_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Tournament Model Evaluation (3/17/21)\n",
    "\n",
    "The distribution of the upsets across the tournament rounds generated by our bracket_pipeline() is very similar to what we observed in our test set, so we need to be mindful of being too conversative with upset predictions in the first round and being too aggressive in the second and third rounds. This aggression is seen in some upset seed pairings such as (3, 11), (1, 12), and (2, 12).\n",
    "\n",
    "Nonetheless, it was very encouraging to see our model predict exactly 20 upsets for the entire tournament. This is right on par with our dataset's historical mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Display bracket_pipeline() predictions by round\n",
    "for _round in bracket_preds['Round'].unique():\n",
    "    display(bracket_preds[bracket_preds['Round'] == _round])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get seed pairs data\n",
    "curr_seed_pairs = get_seed_pairs(bracket_preds)\n",
    "# Extract seed pairs that resulted in upsets\n",
    "curr_upset_pairs = curr_seed_pairs[curr_seed_pairs['Underdog_Upset'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Group upset seed pairs by round and count them\n",
    "curr_upset_rounds_freq = curr_upset_pairs['Round'].value_counts(normalize=True)\n",
    "\n",
    "# Plot findings\n",
    "curr_upset_rounds_freq.plot(figsize=(9, 6), kind='bar', rot=0)\n",
    "\n",
    "format_plot(title='Current Upsets by Round', xlabel='Round', ylabel='Ratio of Upsets')\n",
    "print(f\"Total Upsets: {len(curr_upset_pairs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Group upsets by seed pairing and count them\n",
    "curr_upset_pairs_freq = curr_upset_pairs['Pairs'].value_counts()\n",
    "\n",
    "# Plot findings\n",
    "curr_upset_pairs_freq.plot(figsize=(9, 6), kind='bar', rot=35)\n",
    "\n",
    "format_plot(title='Current Upsets by Seed Pair', xlabel='Seed Pair', ylabel='Ratio of Upsets')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Post-Tournament Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion & Future Work"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
