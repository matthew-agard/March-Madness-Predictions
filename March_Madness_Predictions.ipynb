{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rk</th>\n",
       "      <th>School</th>\n",
       "      <th>G</th>\n",
       "      <th>W</th>\n",
       "      <th>L</th>\n",
       "      <th>W-L%</th>\n",
       "      <th>SRS</th>\n",
       "      <th>SOS</th>\n",
       "      <th>Unnamed: 8</th>\n",
       "      <th>W.1</th>\n",
       "      <th>...</th>\n",
       "      <th>FT</th>\n",
       "      <th>FTA</th>\n",
       "      <th>FT%</th>\n",
       "      <th>ORB</th>\n",
       "      <th>TRB</th>\n",
       "      <th>AST</th>\n",
       "      <th>STL</th>\n",
       "      <th>BLK</th>\n",
       "      <th>TOV</th>\n",
       "      <th>PF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Air Force</td>\n",
       "      <td>28</td>\n",
       "      <td>9</td>\n",
       "      <td>19</td>\n",
       "      <td>.321</td>\n",
       "      <td>-7.45</td>\n",
       "      <td>2.05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>409</td>\n",
       "      <td>584</td>\n",
       "      <td>.700</td>\n",
       "      <td>NaN</td>\n",
       "      <td>965</td>\n",
       "      <td>285</td>\n",
       "      <td>178</td>\n",
       "      <td>109</td>\n",
       "      <td>385</td>\n",
       "      <td>546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Akron</td>\n",
       "      <td>26</td>\n",
       "      <td>8</td>\n",
       "      <td>18</td>\n",
       "      <td>.308</td>\n",
       "      <td>-10.69</td>\n",
       "      <td>-5.07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>320</td>\n",
       "      <td>493</td>\n",
       "      <td>.649</td>\n",
       "      <td>NaN</td>\n",
       "      <td>795</td>\n",
       "      <td>316</td>\n",
       "      <td>163</td>\n",
       "      <td>47</td>\n",
       "      <td>352</td>\n",
       "      <td>573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Alabama-Birmingham</td>\n",
       "      <td>35</td>\n",
       "      <td>21</td>\n",
       "      <td>14</td>\n",
       "      <td>.600</td>\n",
       "      <td>10.82</td>\n",
       "      <td>5.68</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>456</td>\n",
       "      <td>650</td>\n",
       "      <td>.702</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1273</td>\n",
       "      <td>501</td>\n",
       "      <td>246</td>\n",
       "      <td>135</td>\n",
       "      <td>498</td>\n",
       "      <td>650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Alabama State</td>\n",
       "      <td>27</td>\n",
       "      <td>14</td>\n",
       "      <td>13</td>\n",
       "      <td>.519</td>\n",
       "      <td>-8.48</td>\n",
       "      <td>-9.70</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>541</td>\n",
       "      <td>767</td>\n",
       "      <td>.705</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1049</td>\n",
       "      <td>393</td>\n",
       "      <td>194</td>\n",
       "      <td>42</td>\n",
       "      <td>556</td>\n",
       "      <td>567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>29</td>\n",
       "      <td>16</td>\n",
       "      <td>13</td>\n",
       "      <td>.552</td>\n",
       "      <td>9.66</td>\n",
       "      <td>7.83</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>458</td>\n",
       "      <td>702</td>\n",
       "      <td>.652</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1117</td>\n",
       "      <td>337</td>\n",
       "      <td>185</td>\n",
       "      <td>120</td>\n",
       "      <td>487</td>\n",
       "      <td>539</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Rk              School   G   W   L  W-L%     SRS    SOS  Unnamed: 8 W.1  \\\n",
       "0  1           Air Force  28   9  19  .321   -7.45   2.05         NaN   3   \n",
       "1  2               Akron  26   8  18  .308  -10.69  -5.07         NaN   3   \n",
       "2  3  Alabama-Birmingham  35  21  14  .600   10.82   5.68         NaN   5   \n",
       "3  4       Alabama State  27  14  13  .519   -8.48  -9.70         NaN   9   \n",
       "4  5             Alabama  29  16  13  .552    9.66   7.83         NaN   7   \n",
       "\n",
       "   ...   FT  FTA   FT%  ORB   TRB  AST  STL  BLK  TOV   PF  \n",
       "0  ...  409  584  .700  NaN   965  285  178  109  385  546  \n",
       "1  ...  320  493  .649  NaN   795  316  163   47  352  573  \n",
       "2  ...  456  650  .702  NaN  1273  501  246  135  498  650  \n",
       "3  ...  541  767  .705  NaN  1049  393  194   42  556  567  \n",
       "4  ...  458  702  .652  NaN  1117  337  185  120  487  539  \n",
       "\n",
       "[5 rows x 38 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from API.fetch.data_fetch import get_team_data\n",
    "\n",
    "start_year = 1993\n",
    "get_team_data(url=f\"https://www.sports-reference.com/cbb/seasons/{start_year}-school-stats.html\",\n",
    "              attrs={'id': 'basic_school_stats'}).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-78352775aeea>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mdata_visualizations\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mget_yearly_base_rates\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mget_seed_pairs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformat_plot\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmodel_selection\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mget_cv_models\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mmodel_evaluation\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mevaluate_cv_models\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mget_classification_report\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\March Madness\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\March Madness\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\March Madness\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_find_spec\u001b[1;34m(name, path, target)\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\March Madness\\lib\\importlib\\_bootstrap_external.py\u001b[0m in \u001b[0;36mfind_spec\u001b[1;34m(cls, fullname, path, target)\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\March Madness\\lib\\importlib\\_bootstrap_external.py\u001b[0m in \u001b[0;36m_get_spec\u001b[1;34m(cls, fullname, path, target)\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\March Madness\\lib\\importlib\\_bootstrap_external.py\u001b[0m in \u001b[0;36mfind_spec\u001b[1;34m(self, fullname, target)\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\March Madness\\lib\\importlib\\_bootstrap_external.py\u001b[0m in \u001b[0;36m_path_stat\u001b[1;34m(path)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Standard Python libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from IPython.display import display\n",
    "import re\n",
    "from datetime import datetime\n",
    "start_year = 1993\n",
    "curr_year = datetime.now().year\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Custom API\n",
    "import data_fetch as fetch\n",
    "from data_pipeline import dataset_pipeline, feature_pipeline, bracket_pipeline\n",
    "from data_visualizations import get_yearly_base_rates, get_seed_pairs, format_plot\n",
    "from model_selection import get_cv_models\n",
    "from model_evaluation import evaluate_cv_models, get_classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Fetching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perceived Predictors\n",
    "\n",
    "Naturally, it will be vitally important to scrape available data that is pertinent to deciding the outcome of an NCAA March Madness game between any two given teams. To successfully do so, we must break down what are generally the most influential elements of a basketball team's success.\n",
    "\n",
    "<br>Overall team performance during the regular season is generally a good indicator of how a team will perform in March Madness. This would be captured by statistics, both basic and advanced, such as the following:\n",
    "<br>**Season Record (%)\n",
    "<br>Conference Record (%); could be important given that the tournament is split into regions\n",
    "<br>Regular Season Record vs. Tourney Opponent (%); set to theoretical discrete probability of 50% if no such matchups exist \n",
    "<br>Strength of Schedule (SOS); measures the difficulty of the teams played (higher number = greater difficulty)\n",
    "<br>Top 25 Ranking (boolean); considered a consensus top-tier team\n",
    "<br>Shots Made per Game (FG, 3P, FT)\n",
    "<br>Point Differential per Game; measures how dominant/unsuccessful you are at outscoring your opponent on average\n",
    "<br>Misc. Team Stats per Game (Rebounds, Assists, Blocks, etc.)**\n",
    "\n",
    "<br>It's important to note that in the NCAA, more so than the NBA, experienced coaches can have just as much of an impact on a game's outcome as the players themselves. Hence, it's reasonable to assume that the following statistics could also be solid indicators:\n",
    "**<br>Coach March Madness Appearances\n",
    "<br>Coach Sweet Sixteen Appearances\n",
    "<br>Coach Final Four Appearances\n",
    "<br>Coach Championships Won**\n",
    "\n",
    "<br>And lastly, we need the data for the structure of the tournaments themselves:\n",
    "**<br>Favorite Seed\n",
    "<br>Underdog Seed\n",
    "<br>Round Number (0-6)\n",
    "<br>Game Outcome (boolean); did the underdog upset the favorite?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Team Regular Season Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fetch.get_team_data(url=f\"https://www.sports-reference.com/cbb/seasons/{start_year}-school-stats.html\",\n",
    "              attrs={'id': 'basic_school_stats'}).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fetch.get_team_data(url=f\"https://www.sports-reference.com/cbb/seasons/{start_year}-advanced-school-stats.html\", \n",
    "              attrs={'id': 'adv_school_stats'}).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Team Rankings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fetch.get_rankings_data(url=f\"https://www.sports-reference.com/cbb/seasons/{start_year}-ratings.html\").head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coach Tournament Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fetch.get_coach_data(url=f\"https://www.sports-reference.com/cbb/seasons/{start_year}-coaches.html\").head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tournament Game Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fetch.get_team_data(url=(\"https://apps.washingtonpost.com/sports/search/?pri_school_id=&pri_conference=&pri_coach\"\n",
    "                   \"=&pri_seed_from=1&pri_seed_to=16&pri_power_conference=&pri_bid_type=&opp_school_id\"\n",
    "                   \"=&opp_conference=&opp_coach=&opp_seed_from=1&opp_seed_to=16&opp_power_conference=&opp_bid_type\"\n",
    "                   f\"=&game_type=7&from={start_year}&to={start_year}&submit=\"), \n",
    "              attrs={'class': 'search-results'}, header=0).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    mm_matchups_df = pd.read_csv('march_madness_hist_data.csv')\n",
    "except FileNotFoundError:\n",
    "    mm_matchups_df = dataset_pipeline(np.arange(start_year, curr_year - 1))\n",
    "    mm_matchups_df.to_csv('march_madness_hist_data.csv', index=False)\n",
    "\n",
    "mm_matchups_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling Missing Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding the Nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "true_nulls = fetch.get_feature_null_counts(mm_matchups_df)\n",
    "true_nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tov_null_fills = [col for col in true_nulls.index if ('TOV' in col)]\n",
    "pf_null_fills = [col for col in true_nulls.index if ('PF' in col)]\n",
    "\n",
    "null_drops = list(set(true_nulls.index) - set(tov_null_fills) - set(pf_null_fills))\n",
    "mm_matchups_df.drop(null_drops, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tov_nulls_rows = fetch.get_null_rows(tov_null_fills, mm_matchups_df)\n",
    "pf_nulls_rows = fetch.get_null_rows(pf_null_fills, mm_matchups_df)\n",
    "\n",
    "display(tov_nulls_rows), display(pf_nulls_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What are the Distributions of the Features We Wish to Impute?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tov_null_years = sorted(list(set(tov_nulls_rows['Year'])))\n",
    "\n",
    "for year in tov_null_years:\n",
    "    print(f\"{year} feature distributions\")\n",
    "    year_df = mm_matchups_df[mm_matchups_df['Year'] == year]\n",
    "    year_df[tov_null_fills].hist(figsize=(10, 5), layout=(len(tov_null_years), len(tov_null_fills)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mm_matchups_df[pf_null_fills].hist(figsize=(10, 5), layout=(1, len(pf_null_fills)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impute TOV Nulls by Season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tov_col_means = mm_matchups_df[tov_nulls_rows.columns].groupby('Year').mean()\n",
    "tov_col_means.loc[tov_null_years]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for year in tov_null_years:\n",
    "    for col in tov_null_fills:\n",
    "        col_fill_rows = tov_nulls_rows[tov_nulls_rows['Year'] == year].index\n",
    "        col_year_mean = np.round(tov_col_means.loc[year, col], 1)\n",
    "        \n",
    "        mm_matchups_df.loc[col_fill_rows, col] = mm_matchups_df.loc[col_fill_rows, col].fillna(col_year_mean)\n",
    "        \n",
    "mm_matchups_df.loc[tov_nulls_rows.index, tov_null_fills]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impute PF Nulls Using Entire Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pf_col_means = mm_matchups_df[pf_null_fills].mean()\n",
    "pf_col_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for col in pf_null_fills:\n",
    "    col_mean = np.round(mm_matchups_df[col].mean(), 1)\n",
    "    mm_matchups_df[col].fillna(col_mean, inplace=True)\n",
    "    \n",
    "mm_matchups_df.loc[pf_nulls_rows.index, pf_null_fills]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis (EDA)\n",
    "\n",
    "As any good data scientist should do, there are a few questions I hope to address in my EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is a Bracket's Accuracy Given Random Guessing in Favor of the Majority Class (Base Rate: Favorite Beats Underdog)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yearly_base_rates = get_yearly_base_rates(mm_matchups_df)\n",
    "mean_base_rate = np.round(yearly_base_rates.mean(), 3)\n",
    "\n",
    "years_ma = 2\n",
    "base_rate_ma = np.round(yearly_base_rates.rolling(years_ma).mean(), 3)\n",
    "\n",
    "plt.figure(figsize=(9, 6))\n",
    "\n",
    "plt.plot(yearly_base_rates.index, [mean_base_rate] * len(yearly_base_rates), color='k', linewidth=3, label=f'Mean ({mean_base_rate})')\n",
    "plt.plot(yearly_base_rates.index, base_rate_ma, color='r', linewidth=3, label=f'{years_ma}-Yr MA')\n",
    "plt.bar(yearly_base_rates.index, yearly_base_rates)\n",
    "\n",
    "format_plot(title='Dataset Base Rate Trends', xlabel='Season', ylabel='Base Rate')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How Often Do Upsets Occur in a Given Year's March Madness? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yearly_upsets = mm_matchups_df.groupby('Year').agg({'Underdog_Upset': ['sum', 'count']})\n",
    "yearly_pct_upsets = yearly_upsets[('Underdog_Upset', 'sum')] / yearly_upsets[('Underdog_Upset', 'count')]\n",
    "\n",
    "pct_upsets_ma = yearly_pct_upsets.rolling(years_ma).mean()\n",
    "mean_pct_upsets = np.round(yearly_pct_upsets.mean(), 3)\n",
    "\n",
    "plt.figure(figsize=(9, 6))\n",
    "\n",
    "plt.plot(yearly_pct_upsets.index, [mean_pct_upsets] * len(yearly_pct_upsets), color='k', linewidth=3, \n",
    "         label=f'Mean ({mean_pct_upsets})')\n",
    "plt.plot(yearly_pct_upsets.index, pct_upsets_ma, color='r', linewidth=3, label=f'{years_ma}-Yr MA')\n",
    "plt.bar(yearly_pct_upsets.index, yearly_pct_upsets)\n",
    "\n",
    "format_plot(title='Dataset Upsets Volume Trends', xlabel='Season', ylabel='Upsets (% of Games)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is the Distribution of Upsets Across Each Tournament Round?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_pairs = get_seed_pairs(mm_matchups_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upset_pairs = seed_pairs[seed_pairs['Underdog_Upset'] == 1]\n",
    "upset_rounds_freq = upset_pairs['Round'].value_counts(normalize=True)\n",
    "upset_rounds_freq.plot(figsize=(9, 6), kind='bar', rot=15)\n",
    "\n",
    "format_plot(title='Dataset Upset Volumes by Round', xlabel='Round', ylabel='% of Upsets')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Which Seeding Combinations are the Most Likely to Produce Upsets?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upset_pairs_freq = np.round(upset_pairs['Pairs'].value_counts(normalize=True)[:25], 3)\n",
    "upset_pairs_freq.plot(figsize=(9, 6), kind='bar', rot=35)\n",
    "\n",
    "format_plot(title='Dataset Upset Volumes by Seed Combo', xlabel='Seed Combo', ylabel='% of Upsets')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering & Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_rounds = mm_matchups_df['Round']\n",
    "mm_matchups_df.drop(['Year', 'Team_Favorite', 'Team_Underdog'], axis=1, inplace=True)\n",
    "\n",
    "scaled_mm_matchups_df = feature_pipeline(mm_matchups_df)\n",
    "X = scaled_mm_matchups_df.drop('Underdog_Upset', axis=1)\n",
    "y = scaled_mm_matchups_df['Underdog_Upset']\n",
    "\n",
    "display(X), display(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What are the Distributions of all our Engineered Features?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.hist(figsize=(15, 10))\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What are the Correlations Between Features?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abs_desc_corr = np.abs(scaled_mm_matchups_df.corr().loc['Underdog_Upset']).sort_values()\n",
    "abs_desc_corr.drop('Underdog_Upset', inplace=True)\n",
    "\n",
    "plt.figure(figsize=(9, 6))\n",
    "plt.barh(abs_desc_corr.index, abs_desc_corr.values)\n",
    "\n",
    "format_plot(title='Target Variable Correlation', xlabel='Absolute Correlation Value', ylabel='Features')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What Features have the Greatest Predictive Power?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier().fit(X, y)\n",
    "\n",
    "# Sort features & their corresponding values in by importance\n",
    "importances = rf.feature_importances_\n",
    "feat_importances = X.columns[np.argsort(importances)]\n",
    "feat_values = np.sort(importances)\n",
    "\n",
    "# Plot feature importances calculated above\n",
    "plt.figure(figsize=(9, 6))\n",
    "plt.barh(feat_importances, feat_values)\n",
    "\n",
    "format_plot(title='Feature Importances', xlabel='Normalized Information Gain', ylabel='Features')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "X_train.drop('Round', axis=1, inplace=True)\n",
    "X_test.drop('Round', axis=1, inplace=True)\n",
    "\n",
    "cv_models = get_cv_models(y)\n",
    "model_performance = evaluate_cv_models(cv_models, X_train, y_train)\n",
    "\n",
    "model_performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_performance[['Mean_Accuracy', 'Mean_AUC']].plot(figsize=(9, 6), kind='barh', xticks=np.arange(0, 0.9, 0.05))\n",
    "\n",
    "format_plot(title='Model Performance', xlabel='Metric Value', ylabel='Model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_performance.loc[['SVM', 'LogReg'], ['Mean_Accuracy_Std', 'Mean_AUC_Std']].plot(\n",
    "    figsize=(9, 6), kind='barh', xticks=np.arange(0.01, 0.05, 0.01)\n",
    ")\n",
    "\n",
    "format_plot(title='Model Stability', xlabel='Standard Deviation (Std)', ylabel='Model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = cv_models['SVM'][-1].best_estimator_\n",
    "y_preds = best_model.predict(X_test)\n",
    "\n",
    "display(best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_game_data = pd.concat([y_test, all_rounds, mm_matchups_df[['Seed_Favorite', 'Seed_Underdog']]], \n",
    "                           join='inner', axis=1).drop('Underdog_Upset', axis=1)\n",
    "test_game_data['Underdog_Upset'] = y_preds\n",
    "\n",
    "test_seed_pairs = get_seed_pairs(test_game_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_upset_pairs = test_seed_pairs[test_seed_pairs['Underdog_Upset'] == 1]\n",
    "test_upset_rounds_freq = test_upset_pairs['Round'].value_counts(normalize=True)\n",
    "test_upset_rounds_freq.plot(figsize=(9, 6), kind='bar', rot=15)\n",
    "\n",
    "format_plot(title='Test Set Upset Volumes by Round', xlabel='Round', ylabel='% of Upsets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_upset_pairs_freq = np.round(test_upset_pairs['Pairs'].value_counts(normalize=True)[:25], 3)\n",
    "test_upset_pairs_freq.plot(figsize=(9, 6), kind='bar', rot=35)\n",
    "\n",
    "format_plot(title='Test Set Upset Volumes by Seed Combo', xlabel='Seed Combo', ylabel='% of Upsets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report = get_classification_report(y_test, y_preds)\n",
    "print(\"Test Set Metrics Report \\n\\n\", report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2021 March Madness Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    curr_bracket_df = pd.read_csv('march_madness_curr_start_bracket.csv')\n",
    "except FileNotFoundError:\n",
    "    curr_bracket_df = fetch.get_current_bracket('http://www.espn.com/mens-college-basketball/tournament/bracket')\n",
    "    curr_bracket_df.to_csv('march_madness_curr_start_bracket.csv', index=False)\n",
    "    \n",
    "play_in = curr_bracket_df[:4]\n",
    "play_in = play_in.reindex([0, 1, 3, 2])\n",
    "\n",
    "first_round = curr_bracket_df[4:]\n",
    "first_round.index = range(len(first_round))\n",
    "\n",
    "display(play_in), display(first_round)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bracket_preds = bracket_pipeline(curr_year, play_in, first_round, best_model, null_drops)\n",
    "display(bracket_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Tournament Model Evaluation (3/17/21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "curr_seed_pairs = get_seed_pairs(bracket_preds)\n",
    "curr_upset_pairs = curr_seed_pairs[curr_seed_pairs['Underdog_Upset'] == 1]\n",
    "\n",
    "curr_upset_rounds_freq = curr_upset_pairs['Round'].value_counts()\n",
    "curr_upset_rounds_freq.plot(figsize=(9, 6), kind='bar', rot=0)\n",
    "\n",
    "format_plot(title='Current Upset Volumes by Round', xlabel='Round', ylabel='% of Upsets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "curr_seed_pairs = get_seed_pairs(bracket_preds)\n",
    "curr_upset_pairs = curr_seed_pairs[curr_seed_pairs['Underdog_Upset'] == 1]\n",
    "\n",
    "curr_upset_pairs_freq = curr_upset_pairs['Pairs'].value_counts()\n",
    "curr_upset_pairs_freq.plot(figsize=(9, 6), kind='bar', rot=35)\n",
    "\n",
    "format_plot(title='Current Upset Volumes by Seed Combo', xlabel='Seed Combo', ylabel='% of Upsets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for _round in bracket_preds['Round'].unique():\n",
    "    display(bracket_preds[bracket_preds['Round'] == _round])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Post-Tournament Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
